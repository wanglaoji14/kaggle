{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2eb30fb-a95f-4183-bbdf-72677a8366f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder, label_binarize, OrdinalEncoder, QuantileTransformer, TargetEncoder\n",
    "from category_encoders import CatBoostEncoder, MEstimateEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression, LinearRegression, BayesianRidge, Ridge\n",
    "\n",
    "from sklearn import set_config\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, root_mean_squared_error, mean_squared_error, precision_recall_curve, make_scorer, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, matthews_corrcoef\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "from colorama import Fore, Style, init\n",
    "from copy import deepcopy\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, StratifiedKFold, KFold, RepeatedKFold, cross_val_score, StratifiedGroupKFold\n",
    "from xgboost import DMatrix, XGBClassifier, XGBRegressor\n",
    "from lightgbm import log_evaluation, early_stopping, LGBMClassifier, LGBMRegressor, Dataset\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from tqdm.notebook import tqdm\n",
    "from optuna.samplers import TPESampler, CmaEsSampler\n",
    "from optuna.pruners import HyperbandPruner\n",
    "from functools import partial\n",
    "from IPython.display import display_html, clear_output\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import gc\n",
    "import re\n",
    "from typing import Literal, NamedTuple\n",
    "from itertools import combinations\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a843c72b-cd8b-4ae5-87ff-f26fb593e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#为预处理数据\n",
    "class Config:\n",
    "\n",
    "        state = 42\n",
    "        n_splits = 10\n",
    "        early_stop = 100\n",
    "        \n",
    "        target = 'y'\n",
    "        train = pd.read_csv(\"data/train.csv\")\n",
    "        test = pd.read_csv(\"data/test.csv\")\n",
    "        submission =pd.read_csv(\"data/sample_submission.csv\")\n",
    "    \n",
    "        original_data = False\n",
    "        outliers = False\n",
    "        log_trf = False\n",
    "        feature_eng = True\n",
    "        missing = False\n",
    "        labels = list(train[target].unique())\n",
    "        topk_interactions = 20\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcf5a28-7add-48dd-b108-2f6e21fd09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDA(Config):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cat_features = self.train.drop(self.target, axis=1).select_dtypes(include=['object']).columns.tolist()\n",
    "        self.num_features = self.train.drop(self.target, axis=1).select_dtypes(exclude=['object']).columns.tolist()\n",
    "        self.data_info()\n",
    "        self.heatmap()\n",
    "        self.dist_plots()\n",
    "        self.cat_feature_plots()\n",
    "        self.target_pie()\n",
    "                \n",
    "    def data_info(self):\n",
    "        data_list = [self.train,self.test]\n",
    "        label_list = ['train','test']\n",
    "        for i in range(2):\n",
    "            data = data_list[i]\n",
    "            label = label_list[i]\n",
    "        \n",
    "            table_style = [{'selector': 'th:not(.index_name)',\n",
    "                            'props': [('background-color', '#3cb371'),\n",
    "                                      ('color', '#FFFFFF'),\n",
    "                                      ('font-weight', 'bold'),\n",
    "                                      ('border', '1px solid #DCDCDC'),\n",
    "                                      ('text-align', 'center')]\n",
    "                            }, \n",
    "                            {'selector': 'tbody td',\n",
    "                             'props': [('border', '1px solid #DCDCDC'),\n",
    "                                       ('font-weight', 'normal')]\n",
    "                            }]\n",
    "            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} head\\n')\n",
    "            display(data.head().style.set_table_styles(table_style))\n",
    "                           \n",
    "            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} info\\n'+Style.RESET_ALL)               \n",
    "            display(data.info())\n",
    "                           \n",
    "            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} describe\\n')\n",
    "            display(data.describe().drop(index='count', columns=self.target, errors = 'ignore').T\n",
    "                    .style.set_table_styles(table_style).format('{:.3f}'))\n",
    "            \n",
    "            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} missing values\\n'+Style.RESET_ALL)               \n",
    "            display(data.isna().sum())\n",
    "        return self\n",
    "    \n",
    "    def heatmap(self):\n",
    "        print(Style.BRIGHT+Fore.GREEN+f'\\nCorrelation Heatmap\\n')\n",
    "        plt.figure(figsize=(7,7))\n",
    "        corr = self.train.select_dtypes(exclude='object').corr(method='pearson')\n",
    "        sns.heatmap(corr, fmt = '0.4f', cmap = 'Greens', annot=True, cbar=False)\n",
    "        plt.show()\n",
    "        \n",
    "    def dist_plots(self):\n",
    "        print(Style.BRIGHT+Fore.GREEN+f\"\\nDistribution analysis\\n\")\n",
    "        df = pd.concat([self.train[self.num_features].assign(Source = 'Train'), \n",
    "                        self.test[self.num_features].assign(Source = 'Test'),], \n",
    "                        axis=0, ignore_index = True)\n",
    "\n",
    "        fig, axes = plt.subplots(len(self.num_features), 2 ,figsize = (18, len(self.num_features) * 6), \n",
    "                                 gridspec_kw = {'hspace': 0.3, \n",
    "                                                'wspace': 0.2, \n",
    "                                                'width_ratios': [0.70, 0.30]\n",
    "                                               }\n",
    "                                )\n",
    "        for i,col in enumerate(self.num_features):\n",
    "            ax = axes[i,0]\n",
    "            sns.kdeplot(data = df[[col, 'Source']], x = col, hue = 'Source', \n",
    "                        palette = ['#3cb371', 'r'], ax = ax, linewidth = 2\n",
    "                       )\n",
    "            ax.set(xlabel = '', ylabel = '')\n",
    "            ax.set_title(f\"\\n{col}\")\n",
    "            ax.grid()\n",
    "\n",
    "            ax = axes[i,1]\n",
    "            sns.boxplot(data = df, y = col, x=df.Source, width = 0.5,\n",
    "                        linewidth = 1, fliersize= 1,\n",
    "                        ax = ax, palette=['#3cb371', 'r']\n",
    "                       )\n",
    "            ax.set_title(f\"\\n{col}\")\n",
    "            ax.set(xlabel = '', ylabel = '')\n",
    "            ax.tick_params(axis='both', which='major')\n",
    "            ax.set_xticklabels(['Train', 'Test'])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "               \n",
    "    def cat_feature_plots(self):\n",
    "        fig, axes = plt.subplots(max(len(self.cat_features), 1), 2 ,figsize = (18, len(self.cat_features) * 6), \n",
    "                                 gridspec_kw = {'hspace': 0.5, \n",
    "                                                'wspace': 0.2,\n",
    "                                               }\n",
    "                                )\n",
    "        if len(self.cat_features) == 1:\n",
    "            axes = np.array([axes])\n",
    "            \n",
    "        for i, col in enumerate(self.cat_features):\n",
    "            ax = axes[i,0]\n",
    "            sns.barplot(data=self.train[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='#3cb371')\n",
    "            ax.set(xlabel = '', ylabel = '')\n",
    "            ax.set_title(f\"\\n{col} Train\")\n",
    "            \n",
    "            ax = axes[i,1]\n",
    "            sns.barplot(data=self.train[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='r')\n",
    "            ax.set(xlabel = '', ylabel = '')\n",
    "            ax.set_title(f\"\\n{col} Test\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def target_pie(self):\n",
    "        print(Style.BRIGHT+Fore.GREEN+f\"\\nTarget feature distribution\\n\")\n",
    "        targets = self.train[self.target]\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.pie(targets.value_counts(), labels=targets.value_counts().index, autopct='%1.2f%%', colors=sns.color_palette('viridis', len(targets.value_counts())))\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3edfbdf-6da3-4802-bdd7-8dbc872dd831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class Transform(Config):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 调用父类 Config 的 __init__ 方法（如果存在）\n",
    "        super().__init__()\n",
    "        t0 = time.time()\n",
    "        # 如果启用 original_data，则将原始数据合并到训练集\n",
    "        if self.original_data:\n",
    "            start = time.time()\n",
    "            # 将目标列转换为 0/1（假设值为 \"yes\" 和 \"no\"）\n",
    "            self.train_org[self.target] = (self.train_org[self.target] == \"yes\").astype(int)\n",
    "            # 合并并去重\n",
    "            self.train = pd.concat([self.train, self.train_org], ignore_index=True).drop_duplicates()\n",
    "            self.train.reset_index(drop=True, inplace=True)\n",
    "            print(f\"[合并原始数据] {time.time()-start:.2f}s\")\n",
    "\n",
    "        \n",
    "        # 获取数值型特征列名（排除 object/bool/category/string）\n",
    "        self.num_features = self.train.drop(self.target, axis=1)\\\n",
    "            .select_dtypes(exclude=['object', 'bool', 'category', 'string']).columns.tolist()\n",
    "        \n",
    "        # 获取类别特征列名（只保留 object/bool/category/string）\n",
    "        self.cat_features = self.train.drop(self.target, axis=1)\\\n",
    "            .select_dtypes(include=['object', 'bool', 'category', 'string']).columns.tolist()\n",
    "\n",
    "        if self.missing:\n",
    "            self.missing_values()\n",
    "\n",
    "        if self.outliers:\n",
    "            self.remove_outliers()\n",
    "\n",
    "        if self.log_trf:\n",
    "            self.log_transformation()\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        self.important_features = self.select_important_features(top_k=20)\n",
    "        print(f\"[特征重要度] {time.time()-start:.2f}s\")\n",
    "\n",
    "        if self.feature_eng and self.important_features:\n",
    "            self.train = self.new_features(self.train, self.important_features)\n",
    "            self.test  = self.new_features(self.test, self.important_features)\n",
    "            self.num_features = self.train.drop(self.target, axis=1)\\\n",
    "                .select_dtypes(exclude=['object', 'bool', 'string', 'category']).columns.tolist()\n",
    "            print(f\"[交互特征] {time.time()-start:.2f}s\")\n",
    "\n",
    "        start = time.time()\n",
    "        self.encode()\n",
    "\n",
    "        print(f\"[总耗时] {time.time()-t0:.2f}s\")\n",
    "        \n",
    "    def __call__(self):\n",
    "        # 保存目标列\n",
    "        self.y = self.train[self.target]\n",
    "        # 保存原始特征\n",
    "        self.X = self.train.drop(self.target, axis=1)\n",
    "        # 保存编码后的特征\n",
    "        self.X_enc = self.train_enc.drop(self.target, axis=1)\n",
    "        return self.X, self.X_enc, self.y, self.test, self.test_enc, self.cat_features, self.num_features\n",
    "    \n",
    "    def encode(self):\n",
    "        self.train_enc = self.train.copy()\n",
    "        self.test_enc = self.test.copy()\n",
    "        \n",
    "        self.cat_features_card = []\n",
    "        for f in self.cat_features:\n",
    "            self.cat_features_card.append(self.train[f].nunique())\n",
    "        \n",
    "        # 创建编码器并仅用训练集类别特征进行 fit\n",
    "        oe = OrdinalEncoder()\n",
    "        oe.fit(self.train_enc[self.cat_features])\n",
    "        \n",
    "        # 分别对训练集和测试集进行 transform\n",
    "        self.train_enc[self.cat_features] = oe.transform(self.train_enc[self.cat_features]).astype(int)\n",
    "        self.test_enc[self.cat_features] = oe.transform(self.test_enc[self.cat_features]).astype(int)\n",
    "        \n",
    "        # 创建标准化器并仅用训练集数值特征进行 fit\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(self.train_enc[self.num_features])\n",
    "\n",
    "        \n",
    "        # 分别对训练集和测试集进行 transform\n",
    "        self.train_enc[self.num_features] = scaler.transform(self.train_enc[self.num_features])\n",
    "        self.test_enc[self.num_features] = scaler.transform(self.test_enc[self.num_features])\n",
    "\n",
    "    def select_important_features(self, top_k=20, task='auto'):\n",
    "        \"\"\"\n",
    "        基于树模型的特征重要度筛选，并记录耗时。\n",
    "        功能：返回用于生成交互项的前 top_k 个重要数值特征。\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Step 1: 构造候选列\n",
    "        feat_cols = [c for c in self.num_features if c in self.train.columns and c != self.target]\n",
    "        if not feat_cols:\n",
    "            print(\"[select_important_features] 无可用数值特征，返回空。\")\n",
    "            return []\n",
    "\n",
    "\n",
    "        # Step 2: 准备训练数据\n",
    "        X_train_imp = self.train[feat_cols]\n",
    "        y_train_imp = self.train[self.target]\n",
    "        is_class = (y_train_imp.nunique() <= 10)\n",
    "\n",
    "        # 轻量模型（示例：ExtraTrees；也可 mutual_info_*）\n",
    "        from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "        model = (ExtraTreesClassifier(n_estimators=200, max_features='sqrt', n_jobs=-1, random_state=self.state)\n",
    "                 if is_class else\n",
    "                 ExtraTreesRegressor(n_estimators=200, max_features='sqrt', n_jobs=-1, random_state=self.state))\n",
    "        model.fit(X_train_imp, y_train_imp)\n",
    "    \n",
    "        importances = model.feature_importances_\n",
    "        top_num_feats = pd.Series(importances, index=feat_cols).sort_values(ascending=False).head(top_k).index.tolist()\n",
    "    \n",
    "        print(f\"[select_important_features] 运行耗时: {time.time()-start_time:.2f} 秒（未编码）\")\n",
    "        return top_num_feats\n",
    "\n",
    "\n",
    "            \n",
    "    def new_features(self, data, top_num_feats=None):\n",
    "        # 创建所有数值特征两两组合的乘积特征\n",
    "        feats = top_num_feats if top_num_feats else self.num_features\n",
    "        for c1, c2 in list(combinations(feats, 2)):\n",
    "            data[f\"{c1}_{c2}\"] = data[c1] * data[c2]\n",
    "        # 将类别特征转换为 category 类型\n",
    "        data[self.cat_features] = data[self.cat_features].astype('category')\n",
    "        return data\n",
    "\n",
    "    def log_transformation(self):\n",
    "        # 对目标列做 log1p 变换\n",
    "        self.train[self.target] = np.log1p(self.train[self.target]) \n",
    "        return self\n",
    "        \n",
    "    def remove_outliers(self):\n",
    "        # 基于 IQR 的异常值去除方法\n",
    "        Q1 = self.train[self.target].quantile(0.25)\n",
    "        Q3 = self.train[self.target].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_limit = Q1 - 1.5 * IQR\n",
    "        upper_limit = Q3 + 1.5 * IQR\n",
    "        self.train = self.train[(self.train[self.target] >= lower_limit) & (self.train[self.target] <= upper_limit)]\n",
    "        self.train.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    def missing_values(self):\n",
    "        # 将类别特征中的缺失值替换为字符串 'NaN'\n",
    "        self.train[self.cat_features] = self.train[self.cat_features].fillna('NaN')\n",
    "        self.test[self.cat_features] = self.test[self.cat_features].fillna('NaN')\n",
    "        return self\n",
    "\n",
    "    def reduce_mem(self, df):\n",
    "        numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64', \"uint16\", \"uint32\", \"uint64\"]\n",
    "        for col in df.columns:\n",
    "        # 修正④：将 dtype 转为字符串再比较\n",
    "            col_type = str(df[col].dtype)\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "                if \"int\" in col_type:\n",
    "                    if c_min >= np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min >= np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min >= np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "                else:\n",
    "                # 修正⑤：第二个分支用 elif，避免覆盖\n",
    "                    if c_min >= np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min >= np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e039cad6-324d-4b68-910f-5d6b360e55e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[select_important_features] 运行耗时: 45.22 秒（未编码）\n",
      "[特征重要度] 45.50s\n",
      "[交互特征] 46.23s\n",
      "[总耗时] 48.20s\n"
     ]
    }
   ],
   "source": [
    "t = Transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bca128a-a271-4657-aa76-7377c7ee4ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cat_features, num_features):\n",
    "    \n",
    "    x_input_cats = layers.Input(shape=(len(cat_features),))\n",
    "    embs = []\n",
    "    for j in range(len(cat_features)):\n",
    "        e = layers.Embedding(t.cat_features_card[j], int(np.ceil(np.sqrt(t.cat_features_card[j]))))\n",
    "        x = e(x_input_cats[:,j])\n",
    "        x = layers.Flatten()(x)\n",
    "        embs.append(x)\n",
    "        \n",
    "    x_input_nums = layers.Input(shape=(len(num_features),))\n",
    "    \n",
    "    x = layers.Concatenate(axis=-1)(embs+[x_input_nums]) \n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = keras.Model(inputs=[x_input_cats,x_input_nums], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a16dbc5-a4d2-4312-9804-fd77e6fa69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "git add *.ipynb\n",
    "git commit -m \"增加了一个模型\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bd0dc-bc5c-48f0-b96a-a604f714f6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb7b74-c0ea-42e0-8038-d77f68fe6e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
